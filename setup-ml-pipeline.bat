@echo off
REM ML Pipeline Setup Script for Windows
REM Automates complete setup: data generation -> model training -> testing

setlocal enabledelayedexpansion

echo.
echo â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
echo â•‘     ğŸ¤– ML Pipeline Setup ^& Training Script (Windows)       â•‘
echo â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo.

cd ai-service

REM Step 1: Check Python
echo [1/6] Checking Python environment...
python --version >nul 2>&1
if errorlevel 1 (
    echo âœ— Python not found
    exit /b 1
)
for /f "tokens=2" %%i in ('python --version 2^>^&1') do set PYTHON_VERSION=%%i
echo   Python: %PYTHON_VERSION%

pip --version >nul 2>&1
if errorlevel 1 (
    echo âœ— pip not found
    exit /b 1
)
echo âœ“ Environment OK
echo.

REM Step 2: Install dependencies
echo [2/6] Installing dependencies...
pip install -q -r requirements.txt
pip install -q pytest pytest-cov
echo âœ“ Dependencies installed
echo.

REM Step 3: Generate training data
echo [3/6] Generating training data...
python data_generator.py
if errorlevel 1 (
    echo âœ— Data generation failed
    exit /b 1
)
echo âœ“ Data generation complete
echo.

REM Step 4: Train models
echo [4/6] Training ML models...
python train_models.py
if errorlevel 1 (
    echo âœ— Model training failed
    exit /b 1
)
echo âœ“ Model training complete
echo.

REM Step 5: Run tests
echo [5/6] Running tests...
pytest test_models.py -q
if errorlevel 1 (
    echo âš  Some tests failed (non-critical)
) else (
    echo âœ“ All tests passed
)
echo.

REM Step 6: Validate models
echo [6/6] Validating models...
python -c "
import joblib
import os
import json

models = {
    'forecast_prophet.pkl': 'Forecast (Prophet)',
    'anomaly_isolation_forest.pkl': 'Anomaly Detection (Isolation Forest)',
    'recommendation_rf.pkl': 'Maintenance Recommendation (Random Forest)',
}

print('\nğŸ“¦ Model Files:')
for model_file, description in models.items():
    path = f'./models/{model_file}'
    if os.path.exists(path):
        size = os.path.getsize(path) / (1024 * 1024)  # MB
        try:
            model = joblib.load(path)
            print(f'  âœ“ {description}: {size:.2f} MB')
        except Exception as e:
            print(f'  âœ— {description}: Load error')
    else:
        print(f'  âœ— {description}: Not found')

print('\nğŸ“Š Training Metrics:')
try:
    with open('./models/metrics.json', 'r') as f:
        metrics = json.load(f)
    for model_type, values in metrics.get('metrics', {}).items():
        print(f'  {model_type}:')
        for metric, value in values.items():
            if isinstance(value, dict):
                continue
            print(f'    {metric}: {value:.3f}' if isinstance(value, float) else f'    {metric}: {value}')
except Exception as e:
    print(f'  Error reading metrics: {e}')
"
echo âœ“ Validation complete
echo.

echo â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
echo âœ… Setup Complete!
echo â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo.
echo Next steps:
echo.
echo 1. Start the AI service:
echo    uvicorn main:app --reload
echo.
echo 2. Test the API:
echo    curl http://localhost:8000/health
echo.
echo 3. View API docs:
echo    http://localhost:8000/docs
echo.
echo 4. Run full suite with Docker:
echo    docker-compose up
echo.

pause
